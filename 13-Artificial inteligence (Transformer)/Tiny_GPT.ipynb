{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Download Data"
      ],
      "metadata": {
        "id": "NGU4wnBDbX_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEDZIqBJIMTb",
        "outputId": "490adb62-282c-4049-c9e4-c2fa3002fc6b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-18 17:31:39--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.1’\n",
            "\n",
            "input.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-07-18 17:31:39 (18.7 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import frameworks and APIs"
      ],
      "metadata": {
        "id": "XEDkQg58bbRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D"
      ],
      "metadata": {
        "id": "AJBCF90RN5q4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualise the data"
      ],
      "metadata": {
        "id": "Z_e_g-QwbfPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read it in to inspect it\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "0kmN0ONXIMP7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look at the first 1000 characters\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFLbW4szIMKh",
        "outputId": "9042f5ae-4790-4173-fe6c-624f2493eb98"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing of Data"
      ],
      "metadata": {
        "id": "_OAiJ-SYbiMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.lower().split()"
      ],
      "metadata": {
        "id": "cc83gxaHRxap"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okxnvBcbR8M1",
        "outputId": "44374a71-cbb3-40f0-84dc-08916d90d0b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = set(text)\n",
        "print(len(unique_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkKO8AKPSlAO",
        "outputId": "ff3ca221-db5c-4ffc-9948-907da4110a10"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(unique_words) }\n",
        "itos = { i:ch for i,ch in enumerate(unique_words) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ' '.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
      ],
      "metadata": {
        "id": "j9Vo70I4YJ7k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encode(text[:20]))\n",
        "print(decode(encode(text[:20])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzqU3VjEbJus",
        "outputId": "4afe78ec-d435-4b7f-e740-157d04bc2113"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22227, 2858, 15367, 17431, 11795, 15518, 15164, 14710, 10556, 18327, 5188, 22691, 18327, 22227, 2858, 12912, 6360, 7368, 21568, 17379]\n",
            "first citizen: before we proceed any further, hear me speak. all: speak, speak. first citizen: you are all resolved rather\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data = []\n",
        "for i in range(len(text)//20):\n",
        "  Chunks_of_data = text[i:i+20]\n",
        "  Data.append(Chunks_of_data)\n",
        "print(len(Data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9TAoyoVcOkd",
        "outputId": "a47a7ccb-3afd-4f77-d44a-3d270a53122e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UlZrfwgkeyCU",
        "outputId": "34761745-97bd-4b65-b6a6-e852da49b490"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'first'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input =[]\n",
        "output = []\n",
        "for i in range(len(Data)):\n",
        "  for k in range(len(Data[i])):\n",
        "    input.append(Data[i][:k+1])\n",
        "    output.append(Data[i][k+1:k+2])"
      ],
      "metadata": {
        "id": "_QBN8Bv_d5MV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input[0:5])\n",
        "print(output[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwoDTxBPfcRv",
        "outputId": "14a97964-1bad-401e-9aaf-00ecef3112b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['first'], ['first', 'citizen:'], ['first', 'citizen:', 'before'], ['first', 'citizen:', 'before', 'we'], ['first', 'citizen:', 'before', 'we', 'proceed']]\n",
            "[['citizen:'], ['before'], ['we'], ['proceed'], ['any']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(output) == len(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTJBqK7Ih_ae",
        "outputId": "fd2796db-c502-4e35-d8bb-984ea073ffd2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = []\n",
        "for t in input:\n",
        "  inputs.append(encode(t))"
      ],
      "metadata": {
        "id": "CYgkg_gCkMT0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGt24RnJk03f",
        "outputId": "1bcffd4d-d879-49b9-86c0-c38aeef05bda"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[22227],\n",
              " [22227, 2858],\n",
              " [22227, 2858, 15367],\n",
              " [22227, 2858, 15367, 17431],\n",
              " [22227, 2858, 15367, 17431, 11795],\n",
              " [22227, 2858, 15367, 17431, 11795, 15518],\n",
              " [22227, 2858, 15367, 17431, 11795, 15518, 15164],\n",
              " [22227, 2858, 15367, 17431, 11795, 15518, 15164, 14710],\n",
              " [22227, 2858, 15367, 17431, 11795, 15518, 15164, 14710, 10556],\n",
              " [22227, 2858, 15367, 17431, 11795, 15518, 15164, 14710, 10556, 18327]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = []\n",
        "for t in output:\n",
        "  outputs.append(encode(t))"
      ],
      "metadata": {
        "id": "YQQNKXDhk208"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl040cTok7-L",
        "outputId": "30655caf-519f-40e8-c369-42ae3c69a208"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2858],\n",
              " [15367],\n",
              " [17431],\n",
              " [11795],\n",
              " [15518],\n",
              " [15164],\n",
              " [14710],\n",
              " [10556],\n",
              " [18327],\n",
              " [5188]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_rectangular(input_list, pad_value=0):\n",
        "    max_length = max(len(sub_list) for sub_list in input_list)\n",
        "    rectangular_list = [sub_list + [pad_value] * (max_length - len(sub_list)) for sub_list in input_list]\n",
        "    return rectangular_list\n",
        "\n",
        "inputs = make_rectangular(inputs)\n",
        "outputs = make_rectangular(outputs)"
      ],
      "metadata": {
        "id": "R57tCcABmgxL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TensorFlow dataset from the vectorized data\n",
        "Inputs = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "Labels = tf.data.Dataset.from_tensor_slices(outputs)"
      ],
      "metadata": {
        "id": "ZlesHRbedCRM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.zip((Inputs, Labels))\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPRI2JijdQT9",
        "outputId": "decddcd9-0556-4ae3-834b-0b83f68e4421"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_ZipDataset element_spec=(TensorSpec(shape=(20,), dtype=tf.int32, name=None), TensorSpec(shape=(1,), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1000\n",
        "\n",
        "# Batch the dataset\n",
        "train_dataset = dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "sGXyEU7koAoh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3RjhUqUoGA-",
        "outputId": "e00152b6-5039-41e4-ecb8-444bf043386c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "203"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "0xkfnkOToLcZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample from the data\n",
        "for inp,out in train_dataset:\n",
        "  break"
      ],
      "metadata": {
        "id": "FF4ftT9Yr6Uv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Architecture, here we have a transformer's decoder architecture"
      ],
      "metadata": {
        "id": "DqC57dqpcWiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "dTXVVWhSGBvA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1)\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "H-Act4uzGDGB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model, length):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.length = length\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "    self.pos_encoding = positional_encoding(length = self.length, depth=self.d_model)\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def call(self, x):\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x"
      ],
      "metadata": {
        "id": "4OqhMuDoGFH8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Sample input matrix\n",
        "matrix = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32)\n",
        "\n",
        "# Create the mask for elements above the main diagonal\n",
        "mask = tf.linalg.band_part(tf.ones_like(matrix, dtype=tf.bool), num_lower=-1, num_upper=0)\n",
        "\n",
        "# Apply the mask using tf.where to replace the elements with -inf\n",
        "result_matrix = tf.where(mask, matrix, tf.constant(float('-inf'), dtype=tf.float32))\n",
        "\n",
        "print(result_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZvqGHGkrT0p",
        "outputId": "fff919d6-4bc3-47a5-c573-cc6156c550f1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[  1. -inf -inf]\n",
            " [  4.   5. -inf]\n",
            " [  7.   8.   9.]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(tf.keras.Model):\n",
        "  def __init__(self,head_size,num_heads):\n",
        "    super().__init__()\n",
        "    self.key = tf.keras.layers.Dense(head_size)\n",
        "    self.query = tf.keras.layers.Dense(head_size)\n",
        "    self.value = tf.keras.layers.Dense(head_size)\n",
        "    self.sm = tf.keras.layers.Softmax()\n",
        "    self.dropout = tf.keras.layers.Dropout(0.2)\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "  def call(self,x):\n",
        "    out = []\n",
        "    B,T,C = x.shape\n",
        "    for _ in range(self.num_heads):\n",
        "      k = self.key(x)\n",
        "      Q = self.query(x)\n",
        "      V = self.value(x)\n",
        "      #print(V.shape)\n",
        "      wei = Q @ tf.transpose(k,perm=[0,2,1]) * C**-0.5\n",
        "      mask = tf.linalg.band_part(tf.ones_like(wei, dtype=tf.bool), num_lower=-1, num_upper=0)\n",
        "      wei = tf.where(mask, wei, tf.constant(float('-inf'), dtype=tf.float32))\n",
        "      wei = self.sm(wei)\n",
        "      #print(wei)\n",
        "      wei = self.dropout(wei)\n",
        "      #print(wei.shape)\n",
        "      wei = wei @ V\n",
        "      out.append(wei)\n",
        "    out = tf.concat([out[i] for i in range(self.num_heads)], axis=2)\n",
        "    #print(out.shape)\n",
        "    return out"
      ],
      "metadata": {
        "id": "SMEEU0hDFjam"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heads = Head(2,3)\n",
        "matrix_data = [[[1, 2, 3], [4, 5, 6]],[[1, 2, 3], [4, 5, 6]]]\n",
        "x = tf.constant(matrix_data, dtype=tf.float32)\n",
        "print(x.shape)\n",
        "heads(x).shape\n",
        "#We need to choose num of heads and head_size in order to gives us the same shape of input (B,T,C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCzA3paFpBYk",
        "outputId": "7284305e-0812-42f9-dbfe-92297ba4f5df"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 2, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 2, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.Model):\n",
        "  def __init__(self, num_heads, head_size,n_embd,dropout):\n",
        "    super().__init__()\n",
        "    self.heads = Head(head_size,num_heads)\n",
        "    self.proj = tf.keras.layers.Dense(n_embd)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "    self.head_size = head_size\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.heads(x)\n",
        "    #x = self.heads(x)  #To add this you need to ensure that the output of the multi head equal the input\n",
        "    x = self.dropout(self.proj(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "lVXQsVLOFmf9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.Model):\n",
        "  def __init__(self,n_embd,dropout):\n",
        "    super().__init__()\n",
        "    self.net = tf.keras.Sequential([\n",
        "               tf.keras.layers.Dense(4 * n_embd),\n",
        "               tf.keras.layers.ReLU(),\n",
        "               tf.keras.layers.Dense(n_embd),\n",
        "               tf.keras.layers.ReLU(),\n",
        "               tf.keras.layers.Dense(1,activation = \"sigmoid\"),\n",
        "               tf.keras.layers.Dropout(dropout)])\n",
        "  def call(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "S29e2yXlFnZ7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(tf.keras.Model):\n",
        "  def __init__(self,num_heads,n_embd,dropout1,dropout2,vocab_size=len(unique_words)):\n",
        "    super(Block,self).__init__()\n",
        "    self.head_size = n_embd // num_heads\n",
        "    self.sa = MultiHeadAttention(num_heads, self.head_size,n_embd,dropout1)\n",
        "    self.ffwd = FeedForward(n_embd,dropout2)\n",
        "    self.ln1 = tf.keras.layers.LayerNormalization()\n",
        "    self.ln2 = tf.keras.layers.LayerNormalization()\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    self.linear = tf.keras.layers.Dense(vocab_size,activation = \"sigmoid\")\n",
        "    self.Embedding = PositionalEmbedding(vocab_size = 25000, d_model = n_embd, length = 2048)\n",
        "\n",
        "  def call(self,x):\n",
        "    x = self.Embedding(x)\n",
        "    x = x + self.sa(self.ln1(x))\n",
        "    #We need a flatten layer\n",
        "    x = x + self.ffwd(self.ln2(x))\n",
        "    x = self.flatten(x)\n",
        "    #print(x.shape)\n",
        "    x = self.linear(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "MMqpAwN1Fpx2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lossclass = tf.keras.losses.CategoricalCrossentropy()"
      ],
      "metadata": {
        "id": "1W6CZd-Cr2Aq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.AdamW(learning_rate = 1e-5)"
      ],
      "metadata": {
        "id": "6NY-MwRP1KOu"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model = Block(8,256,0.2,0.2)"
      ],
      "metadata": {
        "id": "q0wKSZZ_1hkN"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        " i = 0\n",
        " v = 0\n",
        " j = 0\n",
        " totalloss = 0\n",
        " Number_of_data = 0\n",
        " l = 0\n",
        " n = 0\n",
        " Number_of_test_data = 0\n",
        " for inputs, targets in train_dataset:\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        output = Model(inputs)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = lossclass(tf.squeeze(tf.one_hot(targets, depth=len(unique_words))), output)\n",
        "\n",
        "    # Compute gradients\n",
        "    gradients = tape.gradient(loss, Model.trainable_variables)\n",
        "\n",
        "    # Update the weights\n",
        "    optimizer.apply_gradients(zip(gradients, Model.trainable_variables))\n",
        "    totalloss += loss\n",
        "    for j in range(len(output)):\n",
        "      if targets[j] == tf.cast(tf.argmax(output, axis=1), dtype=tf.int32).numpy()[j]:\n",
        "        v = v+1\n",
        "    i += 1\n",
        "    Number_of_data += len(output)\n",
        " accuracy = v/(Number_of_data)\n",
        " print(f\"Epoch {epoch+1}: Loss = {totalloss / i}, number of batch in the data : {i} ,Number of data: {Number_of_data}, accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYXkvXBl1LfH",
        "outputId": "4644b622-ae94-4305-c33a-693a85a1bd99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7d19e19cc5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7d19e19cc5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 8.143553733825684, number of batch in the data : 203 ,Number of data: 202640, accuracy: 0.036439005132254246\n",
            "Epoch 2: Loss = 6.744871139526367, number of batch in the data : 203 ,Number of data: 202640, accuracy: 0.0704747335175681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.argmax(output, axis=1)[1]"
      ],
      "metadata": {
        "id": "Tgnuay8Y1sy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QP4NV8FI2pgc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}